# The Seizing Mind: Unraveling the Role of Need for Closure in Misinformation Acceptance
## 1 Conceptual Foundations: Defining Need for Closure and Misinformation Acceptance

This chapter establishes the foundational theoretical constructs for the report, providing precise, data-driven definitions of 'need for closure' and 'misinformation acceptance' to frame the subsequent analysis. It systematically synthesizes the reference materials to define the need for closure as a motivational 'stopping mechanism' characterized by urgency (seizing) and permanence (freezing), detailing its five core sub-dimensions as operationalized by the Need for Closure Scale (NFCS). Concurrently, it defines misinformation acceptance by distinguishing it from related concepts like disinformation and the continued influence effect, outlining key cognitive mechanisms such as source monitoring errors and processing fluency. The chapter's role is to create a clear, evidence-based conceptual vocabulary and framework, directly anchoring the report's core research question in established psychological scales and theories.

### 1.1 The Motivational Architecture of Need for Closure

The **need for closure (NFC)** is a fundamental epistemic motivation, defined as **a desire for a definite answer to a question, as opposed to uncertainty, confusion, or ambiguity**[^1]. It functions as a motivational "stopping mechanism" that applies "brakes" to the open-ended process of generating and testing hypotheses, allowing for crystallized judgments to form[^1]. This desire for certainty manifests in specific behavioral and cognitive tendencies: individuals with high NFC value order, dislike ambiguity, make decisions and form impressions quickly, and tend to hold strong opinions[^2].

To measure this latent construct, Arie Kruglanski and colleagues developed the **Need for Closure Scale (NFCS)**. The scale, originally published in 1994 and later refined, operationalizes NFC through five distinct but related sub-dimensions[^2][^3]. The NFCS can be computed as a total score or as separate sub-scale scores. The following table summarizes these core dimensions and provides illustrative sample items:

| Sub-Scale Designation | Core Dimension Measured | Illustrative Sample Item (Paraphrased) |
| :--- | :--- | :--- |
| ‘a’ | **Preference for Order and Structure** | "I think that having clear rules and order at work is essential for success."[^3] |
| ‘b’ | **Desire for Predictability** | "I don't like to go into a situation without knowing what I can expect from it."[^3] |
| ‘c’ | **Decisiveness** | "I usually make important decisions quickly and confidently."[^3] |
| ‘d’ | **Discomfort with Ambiguity / Intolerance of Ambiguity** | "I'd rather know bad news than stay in a state of uncertainty."[^3] |
| ‘e’ | **Closed-Mindedness** | "I do not usually consult many different opinions before forming my own view."[^3] |

**The NFCS comes in two primary versions: a full 41-item questionnaire and a short 15-item version**[^2]. The scale's purpose is to assess an individual's "motivation with respect to information processing and judgment," specifically the desire for an answer that ends further processing, even if it is not optimal[^3].

Critically, NFC is conceptualized as existing on a single motivational continuum. At the opposite pole lies the **need to avoid closure**, which is elevated when the perceived benefits of lacking closure (e.g., enjoying ambiguity) or the perceived costs of possessing closure (e.g., fear of being wrong) are high[^1]. An individual's position on this continuum is influenced by both stable personality differences and situational factors, such as time pressure or fatigue, which can temporarily heighten the desire for certainty[^1].

### 1.2 Deconstructing Misinformation: From Exposure to Acceptance

To understand its acceptance, one must first precisely define misinformation and distinguish it from related phenomena. **Misinformation** is formally defined as **false or inaccurate information—getting the facts wrong**[^4]. Its crucial characteristic is that it is spread **without deliberate intent to deceive**; the sharer may be unaware of its inaccuracy[^5]. In contrast, **disinformation** is **false information which is deliberately intended to mislead—intentionally misstating the facts**[^4]. The key distinction lies in the **speaker's intent**[^5]. Both forms of false information pose significant societal risks, affecting public health efforts, climate change action, and democratic stability[^4].

This report moves beyond mere exposure to focus on **misinformation acceptance**—the psychological state where an individual believes in, endorses, or relies upon false claims. This must be differentiated from two other key concepts:
*   **The Misinformation Effect:** This refers to a memory distortion where exposure to misleading information after an event alters one's memory of the original event.
*   **The Continued Influence Effect (CIE):** This is a critical phenomenon where **misinformation continues to influence people's reasoning and beliefs even after it has been credibly corrected**[^6]. The CIE highlights the persistent challenge of misinformation, as correction alone is often insufficient to eliminate its impact.

Therefore, misinformation acceptance is the dependent variable of interest, encompassing both initial belief and the lingering influence captured by the CIE.

### 1.3 Cognitive Mechanisms Underpinning Misinformation Acceptance

Psychological research has identified several core cognitive mechanisms that explain why individuals accept misinformation. Two of the most prominent are source monitoring failures and the misuse of processing fluency.

**Source Monitoring Failures** involve difficulties in correctly attributing the origin of a piece of information. When we encounter information, we encode both its content and details about its source (e.g., who said it, where we read it). Failures in **recalling or binding the source to the content** can lead to accepting misinformation, especially if the content itself feels familiar or plausible[^6]. For instance, one might remember a false claim but forget it came from an unreliable social media post, mistakenly attributing it to a credible news report later.

**Processing Fluency and the Illusory Truth Effect** is a central mechanism. **Processing fluency** is the subjective ease with which our minds process information. A key finding is that **mere repetition of a statement increases its perceived truth**, a robust phenomenon known as the **illusory truth effect**[^6]. Repetition makes information easier to process (more fluent), and this feeling of fluency is often misattributed as a signal of truthfulness[^6]. Importantly, this effect occurs **even for known falsehoods and across different levels of cognitive ability**[^6]. The mechanism suggests that people often use a "feelings-as-information" heuristic, where the ease of processing is taken as a cue for validity, bypassing more analytical reasoning.

These cognitive accounts provide the foundational "how" of misinformation acceptance. The subsequent chapters will explore how the motivational force of Need for Closure interacts with and potentially exacerbates these underlying cognitive vulnerabilities.

## 2 Theoretical Pathways: How Need for Closure May Drive Misinformation Acceptance

This chapter synthesizes theoretical and empirical evidence to construct and analyze the primary causal pathways through which a heightened need for closure (NFC) increases susceptibility to misinformation acceptance. Building on the foundational cognitive mechanisms established in Chapter 1, it focuses on how NFC's core motivational dynamics—urgency (seizing) and permanence (freezing)—systematically bias information processing. The analysis leverages reference materials to detail pathways including: the 'seize-and-freeze' dynamic leading to heuristic reliance and reduced analytical thinking; the amplification of cognitive biases like the illusory truth effect; the role of source characteristics (e.g., in-group, authority) as simplifying cues; and the potential for motivated reasoning to protect frozen beliefs. This chapter serves as the core theoretical bridge, connecting the established constructs to specific, testable mechanisms that explain why and how NFC facilitates belief in false claims.

### 2.1 The Seize-and-Freeze Dynamic: Reducing Systematic Processing and Amplifying Heuristics

The most direct pathway linking NFC to misinformation acceptance is through the **"seize-and-freeze" dynamic**, a cognitive-motivational process that systematically reduces engagement in effortful, analytical reasoning. Individuals with a high NFC are driven by an **urgency tendency ("seizing")** to attain a quick, definitive answer to resolve uncertainty[^6]. This desire for rapid closure makes them **less likely to engage in effortful processing of information** and more inclined to rely on intuitive, heuristic-based judgments[^6]. Consequently, they may accept information that feels familiar or is easy to process without scrutinizing its factual basis.

This pathway is strongly supported by comparative cognitive modeling. Studies that pit different theoretical models against each other find that **classical reasoning models—which posit that analytical thinking increases the likelihood of correctly identifying misinformation—consistently outperform models based on motivated reasoning**[^7]. For instance, models incorporating Cognitive Reflection Test (CRT) scores, a measure of analytical thinking, achieve high predictive accuracy for whether an individual will accept or reject a news item[^7]. **The success of these analytical models highlights that a lack of deliberate reasoning is a key vulnerability exploited by misinformation.** The NFC-driven "seizing" impulse directly undermines this protective analytical engagement.

Furthermore, the **permanence tendency ("freezing")** reinforces this vulnerability. Once a judgment is formed to achieve closure, individuals with high NFC exhibit a strong drive to maintain it, leading to rigidity and **resistance to contradictory information**[^6]. This means that not only is misinformation more likely to be accepted initially due to heuristic processing, but that belief is also more likely to become entrenched and resistant to update. **This dual process of rapid, shallow acceptance followed by defensive maintenance creates a potent pathway for misinformation to take hold and persist.**

### 2.2 Misinterpreting Fluency: NFC and the Amplification of the Illusory Truth Effect

A second critical pathway involves the interaction between NFC and the core cognitive mechanism of **processing fluency**. As established in Chapter 1, repetition increases processing fluency, which people often misinterpret as a signal of truth, leading to the **illusory truth effect**. NFC can amplify this effect, creating a specific vulnerability to repeated falsehoods.

The desire for certainty inherent in high NFC may make individuals **more susceptible to the influence of processing fluency when judging truth because fluency provides a subjective sense of certainty**[^6]. When information feels easy to process (e.g., because it has been encountered before), it feels more coherent and less ambiguous—qualities that directly satisfy the need for closure. **Therefore, high-NFC individuals may be particularly prone to using the heuristic "if it feels fluent, it is true,"** even for implausible statements or known falsehoods[^6][^8].

Empirical investigations confirm the robustness of this interaction. Research has shown that the illusory truth effect persists **across individual differences in cognitive ability, need for cognitive closure, and cognitive style**[^6][^9]. This robustness indicates that the fluency-to-truth heuristic is a powerful and general cognitive shortcut, but one whose effects are not diminished by a high NFC; in fact, the motivational state may increase reliance on it. **The pathway is clear: environments saturated with repeated false claims (e.g., social media) generate high fluency for those claims. Individuals with high NFC, seeking to reduce ambiguity, are then more likely to interpret that fluent feeling as truth, thereby accepting the misinformation.**

### 2.3 Source as a Simplifying Cue: Prioritizing In-Group and Authority over Accuracy

NFC also drives misinformation acceptance by shaping how individuals evaluate information **sources**. To achieve quick and stable closure, high-NFC individuals often use source characteristics as simplifying heuristic cues, potentially prioritizing these cues over a detailed analysis of content accuracy.

A primary cue is **social identity**. Individuals are consistently **more persuaded by messages from in-group than out-group members**[^6]. For someone with high NFC, trusting information from a perceived in-group source (e.g., a political ally, a community leader) provides a socially validated, ready-made answer that reduces the need for personal information search and evaluation. This heuristic can lead to the acceptance of misinformation if it originates from a trusted in-group source.

Similarly, **perceived authority or credibility** serves as a potent shortcut. **Source credibility influences the acceptance of information and the effectiveness of corrections**[^6]. High-NFC individuals, with their **preference for order and predictability**, may find it simpler and more certain to defer to an authoritative-seeming source than to navigate complex, contradictory evidence themselves[^6]. This can result in accepting misinformation from figures or institutions perceived as credible. However, it is important to note that simply emphasizing publisher identity on social media has been found **not to effectively reduce susceptibility to misinformation**, suggesting the heuristic is applied passively rather than as an active critical tool[^6][^10].

**This pathway underscores a strategic trade-off: the motivational goal of achieving cognitive closure can override the epistemic goal of accuracy.** By using source as a proxy for truth, high-NFC individuals can efficiently form judgments, but this efficiency comes at the cost of increased vulnerability to misinformation propagated by sources they find socially or authoritatively comforting.

### 2.4 Protecting Frozen Beliefs: NFC, Motivated Reasoning, and Resistance to Correction

The final pathway addresses how NFC contributes to the **persistence of misinformation after correction**, known as the continued influence effect (CIE). Here, the "freezing" dynamic is paramount. Once misinformation has been accepted and integrated into a person's mental model to provide closure, high NFC motivates defensive processes to **protect that frozen belief from threatening contradictory evidence**.

A critical insight from the reference materials is that the role of motivated reasoning may differ between initial acceptance and subsequent correction. Cognitive modeling studies show that formal **motivated reasoning models perform poorly in predicting initial acceptance of misinformation**, with accuracy only slightly above random[^7]. This suggests that biased, identity-protective reasoning is not the primary driver of first believing a false claim.

However, NFC is explicitly discussed as a factor that increases susceptibility and contributes to the **psychological barriers to knowledge revision after misinformation has been corrected**[^6]. After closure is achieved, the presentation of a correction introduces new ambiguity, challenging the frozen belief. To maintain closure, high-NFC individuals may then engage in **motivated reasoning to dismiss, discredit, or avoid the corrective information**[^6]. This reasoning is not necessarily to uphold a partisan identity, but to defend the cognitive stability that the (now false) belief provides.

This defensive pathway is supported by research on individual differences in correction efficacy. **Fluid intelligence—the ability to reason and solve novel problems—is consistently associated with a more pronounced correction effect**, indicating a greater capacity to update beliefs in the face of new evidence[^11]. In contrast, the **motivation to think deeply (Need for Cognition) does not significantly affect the size of the correction effect**[^11]. **This dissociation highlights that successfully overcoming misinformation depends more on cognitive ability than on thinking motivation, but that the motivation for certainty (NFC) can actively work against this updating process by promoting defensive freezing.**

In synthesis, NFC facilitates misinformation acceptance through a sequence of interlinked pathways: it promotes rapid, heuristic-driven initial acceptance (seizing), amplifies the deceptive feeling of truth from repetition, favors information from simple source cues, and then drives resistance to subsequent corrections to protect the achieved closure (freezing). These pathways collectively explain how the deep-seated motivation for certainty can systematically undermine the pursuit of accuracy in the modern information environment.

## 3 Empirical Evidence: A Synthesis of Research Findings

This chapter critically synthesizes empirical research to assess the strength, mechanisms, and boundary conditions of the relationship between need for closure (NFC) and misinformation acceptance. The analysis reveals a nuanced picture: while NFC is consistently linked to greater susceptibility, its independent effect is often modest and must be understood within a broader ecosystem of cognitive and social factors. The evidence is drawn from three complementary domains: large-scale correlational surveys, experimental and clinical studies on specific cognitive biases, and comparative cognitive modeling that pits different theoretical accounts against each other. This synthesis grounds the theoretical pathways from Chapter 2 in concrete data, clarifies the distinct role of NFC, and identifies key moderators and unresolved contradictions.

### 3.1 Direct Correlational Evidence: NFC, Conspiracy Beliefs, and Misinformation Susceptibility

Large-scale, longitudinal surveys provide the most direct evidence for the NFC-misinformation link in real-world contexts. A pivotal series of studies used a representative German population sample (N = 2,883) to assess NFC and general political trust *before* the COVID-19 pandemic, and then measured belief in COVID-19 conspiracy theories during the pandemic's second wave[^12]. This design strengthens causal inference by establishing temporal precedence of the hypothesized cause.

The findings present a clear but qualified relationship. At the bivariate level, **NFC shows a consistent, weak positive association with belief in conspiracy theories**[^12][^10]. This supports the exploratory hypothesis that a higher need for closure predicts greater acceptance of simplistic, conspiratorial narratives[^10]. However, the critical insight emerges from multivariate regression analyses that account for other factors. While NFC remains a statistically significant predictor, **its effect size is consistently reported as "small" or "relatively small" compared to other variables**[^12][^10][^12].

**The most powerful predictors in these models are not cognitive motivations like NFC, but measures of trust.** Both pre-pandemic political trust and concurrent trust in political and medical institutions during the crisis are **"strongly negatively related to conspiracy beliefs" and are identified as "the most influential factors"**[^12][^10][^12]. Regression models explaining between 20.7% and 36.8% of the variance underscore that a **lack of institutional trust is a far more substantial driver of conspiracy belief than individual differences in epistemic motivation**[^12][^10][^12].

A crucial boundary condition is established regarding the interplay between NFC and trust. The studies explicitly tested the hypothesis that political trust moderates the relationship between NFC and conspiracy acceptance (e.g., that high NFC only leads to belief when trust is low). **The results uniformly found "no support for a moderating effect of political trust"**[^12][^10]. NFC and trust operated as independent main effects, with trust exerting a much stronger influence.

Furthermore, the distribution of beliefs themselves provides context. At the time of the survey, most citizens were not susceptible to COVID-19 conspiracy theories (e.g., only 7.8% thought it very likely the virus was a biological weapon), with a mean belief index of 2.50 on a seven-point scale[^12]. This indicates that while NFC is a risk factor, widespread belief in false narratives cannot be attributed to it alone.

**In summary, the direct correlational evidence establishes NFC as a consistent but minor risk factor for misinformation acceptance.** Its role is eclipsed by the profound impact of political and institutional distrust, which appears to be the primary societal-level vulnerability exploited by misinformation[^10][^12].

### 3.2 Experimental and Clinical Insights: NFC, Cognitive Biases, and Information Processing

Beyond correlations, experimental research illuminates the specific cognitive mechanisms through which NFC operates, particularly its role in amplifying heuristic processing and fostering resistance to information updating. A key concept here is the **"break-in-the-message" effect**, where a temporal break between a simplistic headline and a subsequent, more nuanced elaboration increases the headline's persuasive impact[^13]. An experiment demonstrated that this effect is **moderated by NFC**. For individuals with low NFC, the time break manipulation had no significant effect on their judgments. **For high-NFC individuals, however, the break led to significantly more severe and punitive moral evaluations based on the initial headline**[^13]. This finding directly illustrates the "seize-and-freeze" dynamic: high-NFC individuals seize on the first available, clear-cut information (the headline) and freeze on that judgment, becoming resistant to the complicating details presented later.

Clinical and subclinical research on reasoning biases offers another mechanistic lens, particularly through the study of the **"jumping-to-conclusions" (JTC) bias**. JTC, defined as making confident decisions based on minimal evidence, is a well-established cognitive feature in individuals with psychosis and delusion-proneness[^14][^15]. Research has investigated whether NFC, as a "motivated need for certainty," drives this hasty data-gathering style[^16].

The evidence reveals a more complex relationship than simple causation. Studies find that **delusion-prone individuals score higher on NFC measures and exhibit the JTC bias**[^15][^16]. However, analyses show **"no evidence of a direct relationship" between NFC and JTC**[^16]. They are independently associated with the outcome, discounting the view that NFC directly motivates a JTC bias which then leads to aberrant beliefs. This suggests that the pathway from NFC to misinformation acceptance in the general population may not primarily involve a deliberate rush to gather little evidence, but rather a preference for accepting readily available, simple answers that provide immediate closure.

Further nuance comes from dissecting the NFC construct itself. In delusion-prone samples, different facets of NFC show **divergent correlations**: **intolerance of ambiguity correlates positively with delusion-proneness, while decisiveness correlates negatively**[^16]. This implies that the indecisiveness and discomfort with ambiguity characteristic of high NFC may be more relevant to misinformation vulnerability than a confident, quick decision-making style. This aligns with the idea that anxiety and uncertainty drive individuals toward any definitive answer, including false ones.

**These experimental and clinical insights confirm that NFC systematically biases information processing.** It makes individuals disproportionately influenced by initial, simplistic information (seizing) and resistant to subsequent corrections or complexities (freezing), and it is linked to a discomfort with ambiguity that may increase the attractiveness of clear-but-false narratives.

### 3.3 Comparative Predictive Power: NFC in the Landscape of Cognitive Modeling

To accurately gauge the significance of NFC, it must be evaluated against other cognitive and motivational factors in predictive models of misinformation acceptance. Large-scale cognitive modeling studies, which systematically compare the performance of different theoretical accounts, provide this comparative landscape.

A comprehensive meta-analysis of 31 studies (256,337 judgments from 11,561 participants) used signal detection theory to disentangle the **ability to discriminate true from false news (discrimination ability)** from the **tendency to label news as true or false (response bias)**[^17]. The analysis identified **analytical thinking (measured by the Cognitive Reflection Test, CRT) as a robust, strong predictor of better discrimination ability**[^17]. Conversely, factors like **ideological congruency and self-reported familiarity had no credible effect on discrimination ability but strongly predicted a "true-news bias" (naïvety)**[^17]. This critical distinction shows that **analytical thinking improves accuracy, while motivational and heuristic factors primarily bias judgments**.

Within this framework, the role of NFC is instructive. Notably, the preregistered analysis of the major meta-analysis **did not include NFC as a primary factor in its main model**[^17]. Its focus was on analytical thinking, ideological congruency, motivated reflection, and familiarity. This itself suggests that, based on the current evidence base, NFC is not considered among the foremost predictors in head-to-head comparative models.

The superior performance of models based on analytical reasoning is a consistent theme. Comparative assessments show that **classical reasoning models (which posit that analytical thinking supports accurate belief formation) achieve high predictive accuracy (e.g., 0.65-0.81), while motivated reasoning models perform poorly (e.g., 0.55-0.59)**[^7][^18]. One study concluded that susceptibility to fake news is **"more strongly linked to lazy thinking (a lack of reasoning) than to partisan bias per se"**[^18]. This directly informs the NFC pathway: **NFC's primary effect may be to *reduce* engagement in the analytical reasoning that protects against misinformation, rather than to *actively motivate* biased reasoning toward a specific conclusion.**

Further contextualization comes from research on **"epistemic vice"**—character traits like indifference to truth that interfere with knowledge. One study found that epistemic vice was **"associated with susceptibility to COVID-19 misinformation"** and that **this association was stronger than with political identity, education, CRT scores, personality, dogmatism, and need for closure**[^19]. This indicates that other stable trait-based barriers to knowledge acquisition may be more consequential than NFC.

The performance of hybrid models in cognitive modeling is also revealing. Models that adaptively select the best prediction for each individual from a toolbox of strategies (e.g., combining recognition heuristics with CRT-based reasoning) achieve the highest accuracy (up to 0.87)[^7]. This suggests individuals use diverse cognitive strategies. The strong performance of CRT-based models within this toolbox underscores the protective value of analytical thinking, a resource that high-NFC states deplete.

**In synthesis, the comparative modeling evidence positions NFC as a contributor to a broader "lazy thinking" or non-analytical processing style, which is a key vulnerability for misinformation acceptance.** Its predictive power is modest relative to the robust effect of analytical thinking ability and appears secondary to other factors like institutional trust and epistemic vice in explaining real-world belief in falsehoods.

## 4 The Digital Amplifier: Need for Closure in Social Media and Algorithmic Environments

This chapter investigates how the structural features of social media platforms and algorithmic curation systems interact with and amplify the psychological vulnerabilities associated with a high need for closure (NFC), thereby increasing susceptibility to misinformation acceptance. The modern information ecosystem does not merely host misinformation; its core operational logic—optimizing for user engagement through algorithmic personalization—creates an environment that systematically caters to and exacerbates the epistemic motivations of high-NFC individuals. By exploiting human attention biases, creating reinforcing feedback loops, and fostering passive consumption habits, these digital architectures provide the quick, clear, and socially validated answers that satisfy the urgency and permanence of NFC. However, the evidence presents a nuanced picture: while algorithms are potent amplifiers, their effects are deeply intertwined with pre-existing human social drivers and psychological traits. This chapter synthesizes the reference materials to analyze the key mechanisms of digital amplification, critically examining the conditions under which algorithms transform from passive reflectors to active catalysts in the pathway from NFC to misinformation acceptance.

### 4.1 Algorithmic Engagement Loops: Exploiting Attention Biases to Satisfy Urgency

The design of social media algorithms creates a powerful engagement loop that directly interacts with and stimulates the ‘seizing’ impulse central to a high need for closure. **These algorithms are engineered to maximize user attention and engagement by ranking content based on signals like likes, comments, and shares, with the goal of serving hyper-personalized content that keeps users on the platform**[^20]. This corporate objective dovetails dangerously with fundamental human psychology. Research shows that **human attention biases toward moral and emotional information are as prevalent online as they are offline**[^21]. When content algorithms, designed to capture attention, interact with these innate biases, they end up privileging and amplifying the very information we are predisposed to attend to—especially misinformation that employs moral and emotional language[^21].

This creates a perfect storm for individuals with high NFC. The ‘urgency’ facet of NFC drives a desire for quick, definitive answers to reduce uncertainty. Algorithmic feeds, optimized for engagement, readily supply rapid-fire, affectively charged content that feels definitive and compelling. **Misinformation exploits this process by leveraging users' impulses to share moral outrage, and algorithms amplify this content because it generates high engagement**[^21]. For example, internal documents from Facebook noted that after a reconfiguration to boost engagement, **viral outrageous and sensationalized content proliferated, with misinformation, toxicity, and violent content being inordinately prevalent among reshares**[^20]. For a high-NFC user, this environment offers a constant stream of simplistic, emotionally resonant narratives that provide immediate cognitive closure, effectively short-circuiting the motivation for more systematic, effortful information processing. The algorithm’s feedback loop—where engaging with such content signals a preference for more of the same—ensures that the user’s feed becomes increasingly tailored to deliver the kind of clear-cut, morally charged answers that satisfy their need for certainty.

### 4.2 Echo Chambers, Filter Bubbles, and the Reinforcement of Frozen Beliefs

Once a high-NFC individual ‘seizes’ upon a piece of information or a worldview, the ‘freezing’ tendency motivates them to maintain that closure and protect it from contradiction. Algorithmic environments can powerfully reinforce this permanence through the creation of personalized information spaces, though the extent and primary cause of this effect are subjects of debate.

**AI-driven recommendation systems are key architects of digital environments that reinforce existing beliefs**, often termed filter bubbles or echo chambers[^22]. A *filter bubble* is a personalized information environment created by algorithms that curate content based on past user behavior, filtering out dissenting perspectives[^22]. An *echo chamber* is an environment where a person is repeatedly exposed to reinforcing viewpoints, solidifying beliefs and blocking opposition, a phenomenon caused by both human choices and algorithmic filter bubbles[^22]. These environments support the ‘freezing’ dynamic by limiting exposure to challenging information and simplifying social cues. **Algorithms reinforce herd behavior—the tendency to conform to group opinions—by prioritizing content with high engagement metrics, which often reflects popular or majority viewpoints within a user’s network**[^23]. This creates a closed loop where a user’s initial leanings are constantly mirrored and amplified back to them, making the belief feel not only correct but socially validated, thereby increasing resistance to change.

However, a critical counter-perspective from the research tempers the view of algorithms as omnipotent creators of polarization. Evidence suggests that **algorithms mostly reinforce existing social drivers rather than being the primary cause of new beliefs**[^24]. A study on Facebook data from 2014 found that **users’ social networks determined posts in their feeds much more strongly than the ranking algorithm did**[^24]. Furthermore, some analyses indicate that **online echo chambers might be smaller than offline ones, meaning people are exposed to more disagreeable views online**[^24]. This exposure can sometimes backfire, as a field experiment on U.S. Twitter observed **increased political polarization after exposure to posts from opinion leaders of the opposing party**[^24].

**This presents a nuanced interaction with NFC: algorithms may not create echo chambers *de novo* for high-NFC individuals, but they excel at reinforcing and rigidifying the user’s existing epistemic choices.** For someone already motivated to avoid ambiguity, actively selecting congenial information sources, the algorithm efficiently optimizes that environment, making it increasingly impermeable. The reinforcement loop strengthens the ‘freeze,’ making the achieved closure more stable and defended. The algorithm thus acts as a force multiplier for pre-existing NFC-driven information-seeking habits, deepening the entrenchment of beliefs, including misinformed ones.

### 4.3 Passive Consumption and Illusory Competence: The ‘News-Finds-Me’ Perception and Overconfidence

The structure of social media fosters a specific pattern of news consumption that interacts synergistically with NFC to undermine analytical vigilance: the **“news-finds-me” (NFM) perception**. This is a belief that one can stay adequately informed through passive exposure to news that circulates within their social media feed or peer network, without needing to actively seek information from traditional news sources[^25]. Studies confirm the prevalence of NFM and demonstrate a **positive association between NFM perception and susceptibility to misinformation**, such as COVID-19 misperceptions[^25][^26]. This relationship is mediated by **information avoidance**, as NFM leads individuals to disengage from active news learning[^25][^26].

For the high-NFC individual, the NFM perception is particularly appealing and dangerous. It offers a path of least cognitive resistance: instead of actively grappling with complex, uncertain information landscapes, one can outsource the information-gathering process to their social feed and its governing algorithm. This satisfies the urgency for answers without requiring cognitive effort. However, this passivity breeds a critical downstream consequence: **overconfidence**. Research reveals a troubling paradox where **those least capable of discerning false news are also the most overconfident in their ability to do so**[^27]. Approximately three-quarters of Americans overestimate their ability to distinguish real from fake news, with the average person placing themselves 22 percentile points higher than their actual performance[^27]. This overconfidence is directly linked to real-world vulnerability; overconfident individuals are **more likely to visit untrustworthy websites, fail to distinguish true from false claims, and express willingness to share false content, especially when it aligns with their views**[^27].

The pathway from NFC to misinformation acceptance through digital habits can thus be mapped as follows: A high need for closure motivates a preference for cognitive ease and definitive answers → This makes the passive, algorithmically-curated NFM mode of consumption attractive → Passive consumption limits exposure to diverse perspectives and depth of information, while the algorithm supplies fluent, repetitive content → This environment fosters an **illusory sense of being informed (overconfidence)** → Overconfidence reduces the perceived need for, and engagement in, critical analysis → This leaves the individual highly susceptible to accepting fluent, emotionally charged, but false information that their personalized feed readily supplies. **This digital overconfidence acts as a meta-cognitive failure that locks in the vulnerabilities created by NFC and amplified by algorithms**[^25].

### 4.4 Synthesizing the Amplification: Algorithmic Environments as NFC Catalysts

Synthesizing the evidence, the modern digital information ecosystem functions as a powerful contextual amplifier of the psychological pathways linking NFC to misinformation acceptance. Its architecture is uniquely suited to exploit and exacerbate the ‘seize-and-freeze’ dynamic.

**The amplification occurs through an interdependent system of mechanisms:** First, engagement-driven algorithms actively **‘seize’ user attention by exploiting moral/emotional biases**, feeding the urgency for clear-cut narratives[^21][^20]. Second, personalization algorithms **‘freeze’ beliefs by creating reinforcing feedback loops** that minimize cognitive dissonance, even if their independent radicalizing effect on individuals may be modest[^22][^24][^23]. Third, the platform ecology encourages a **passive “news-finds-me” mentality** that appeals to the NFC desire for effortless closure, which in turn cultivates **digital overconfidence**, a key trait that blinds individuals to their own susceptibility[^25][^27].

However, this amplification is not absolute or unilateral. The reference materials consistently highlight the **complex feedback loop between human behavior and algorithms**[^24]. Humans strive for status and connection, and they adapt their behavior to gain the rewards (likes, visibility) that algorithms dispense. Algorithms, in turn, adapt to this behavior. **Observable outcomes, including polarization and misinformation spread, are thus the product of interaction, not algorithmic determinism**[^24]. Furthermore, the societal impact may be more about **increasing perceived polarization by making extreme voices more visible, rather than drastically shifting the actual beliefs of the moderate majority**[^24].

Therefore, the role of digital platforms is best understood as that of a **catalyst**. For an individual with a high dispositional or situational need for closure, the platform’s structural features dramatically lower the barrier to seizing on misinformation and raise the barrier to unfreezing those beliefs. It provides the means, the social proof, and the constant reinforcement. **While algorithms may not be the root cause of NFC or societal polarization, they have created an information environment that systematically rewards and reinforces the cognitive patterns associated with NFC, thereby accelerating and scaling the acceptance and persistence of misinformation.** This understanding underscores that interventions must target not only individual psychology but also the design of the digital architectures that shape our information consumption.

## 5 Implications and Interventions: From Theory to Practice

This chapter synthesizes the theoretical pathways and empirical evidence from previous chapters to delineate the concrete societal consequences of the link between need for closure (NFC) and misinformation acceptance, and to critically evaluate evidence-based intervention strategies. The analysis of societal implications will focus on how NFC-driven cognitive patterns contribute to political polarization, the erosion of institutional and interpersonal trust, and specific challenges to public health governance. The intervention analysis will be structured around two core principles derived from the evidence: countering the 'seize-and-freeze' dynamic and mitigating the amplification by digital environments. It will assess the efficacy and applicability of strategies including fostering epistemic humility and analytical thinking, designing choice architectures to encourage deliberation, tailoring media literacy to address NFC-specific biases like the break-in-the-message effect, and implementing platform-level changes to reduce exposure to ambiguous or emotionally charged misinformation. This chapter serves as the actionable conclusion of the report, translating psychological insights into practical recommendations for individuals, educators, policymakers, and technology platforms.

### 5.1 Societal Consequences: Polarization, Erosion of Trust, and Public Health Challenges

The psychological link between a heightened need for closure (NFC) and misinformation acceptance has profound and tangible consequences for society. These consequences manifest most acutely in three interconnected domains: the deepening of political polarization, the systemic erosion of trust, and the direct undermining of public health initiatives.

**First, the 'seize-and-freeze' dynamic directly fuels political polarization.** Individuals with high NFC are motivated to quickly seize on clear, definitive narratives that align with their pre-existing social identities and then freeze on those beliefs, becoming resistant to contradictory evidence[^6]. This process is exacerbated in digital environments where algorithms reinforce in-group perspectives. The result is not merely disagreement but a hardened, parallel reality where opposing sides operate with incompatible foundational facts. **This cognitive rigidity makes constructive political discourse nearly impossible, as corrections are psychologically rejected not on their merits but because they threaten hard-won cognitive closure.** Research indicates that while corrections can be effective, their success is often partial, and misinformation exerts a lingering influence—the continued influence effect—which is sustained by the desire to maintain frozen cognitive structures[^6]. This dynamic transforms political debates from contests over policy into clashes over fundamental reality, eroding the shared epistemic ground necessary for democratic functioning.

**Second, the relationship between NFC and institutional distrust creates a vicious cycle that corrodes social cohesion.** Empirical evidence clearly shows that **a lack of political and institutional trust is the single most powerful predictor of belief in conspiracy theories and misinformation**, such as those surrounding COVID-19[^6]. While NFC is a consistent but smaller risk factor, its interaction with distrust is particularly damaging. High-NFC individuals, uncomfortable with ambiguity, are drawn to simplistic conspiracy narratives that provide clear, cause-and-effect explanations for complex events, especially when authoritative institutions are perceived as untrustworthy or opaque. **This synergy means that in times of crisis or social change, societies with low institutional trust and populations with high dispositional or situationally-induced NFC are exceptionally vulnerable to widespread misinformation acceptance.** The consequence is a delegitimization of expertise, science, and governance, making collective action and evidence-based policymaking extraordinarily difficult.

**Third, public health governance faces acute challenges from NFC-driven misinformation.** The COVID-19 pandemic served as a case study in how these psychological factors can impede crisis response. Misinformation about the virus's origins, false treatments, and vaccine safety spread rapidly. **Emotional appeals, particularly those leveraging anger, have been shown to contribute significantly to the spread and acceptance of such COVID-19 misinformation**[^6]. For high-NFC individuals, these emotionally charged, simplistic narratives offer a way to resolve the anxiety and uncertainty of the pandemic. The resulting vaccine hesitancy and non-compliance with public health measures (e.g., mask-wearing, social distancing) were not merely differences of opinion but were often rooted in misinformed beliefs resistant to correction. **This demonstrates that the societal cost of the NFC-misinformation link is measured in preventable illness and death, as well as in the prolonged duration and economic impact of public health crises.** The erosion of trust in medical authorities further complicates future health communication, creating a long-term vulnerability.

In summary, the societal implications extend far beyond individual false beliefs. **They threaten the integrity of democratic processes, dissolve the glue of social trust, and directly compromise societal resilience in the face of existential challenges like pandemics and climate change.** Addressing these consequences requires moving beyond merely debunking false claims to fundamentally understanding and intervening in the motivational and environmental systems that drive their acceptance.

### 5.2 Intervention Strategies: Countering Seize-and-Freeze and Digital Amplification

Effective interventions must be dual-pronged, targeting both the internal psychological mechanisms of the 'seize-and-freeze' dynamic and the external digital architectures that amplify it. The following table synthesizes evidence-based strategies across these two fronts:

| Intervention Target | Core Strategy | Specific Tactics & Evidence | Key Insight |
| :--- | :--- | :--- | :--- |
| **Internal: Countering 'Seize'** | **Foster Analytical Thinking & Epistemic Humility** | Encourage an **"initial accuracy focus"** when encountering information, which has been shown to prevent the illusory truth effect[^6]. Promote engagement in deliberate reasoning, as **analytical thinking (measured by CRT) is a robust predictor of the ability to discern true from false news**[^6]. | **Protection comes from engaging System 2 thinking before a judgment is formed.** Simply providing more information after the fact is less effective. |
| **Internal: Countering 'Freeze'** | **Utilize Effective Debunking & Correction** | Employ **refutational fact-checks** that explicitly state the myth, label it as false, and provide a factual alternative with a causal explanation[^6]. Ensure corrections come from **credible sources**, as source credibility influences correction acceptance[^6]. Be mindful that **repeating the misinformation within the correction can backfire** by increasing its familiarity[^6]. | **Corrections must compete with the integrated mental model.** Successful debunking requires overwriting the narrative, not just negating it. |
| **Internal: Pre-emptive Defense** | **Implement Psychological Inoculation (Prebunking)** | Expose individuals to **weakened doses of misleading argumentation techniques** (e.g., false dichotomies, emotional manipulation) and teach them how to recognize and refute them. This approach has demonstrated **cross-cultural effectiveness and long-term resilience** against misinformation[^6]. | **It is easier to build cognitive antibodies before exposure than to cure the infection after.** Inoculation empowers individuals to critically evaluate persuasion attempts. |
| **External: Mitigating Digital Triggers** | **Tailor Media Literacy to NFC Biases** | Develop training modules that specifically address **the "break-in-the-message" effect**. Educate users that a temporal gap between a sensational headline and detailed elaboration can lead to over-reliance on the initial, simplistic information, especially for those with high NFC[^13]. Teach **"lateral reading"**—verifying information by checking other sources—as a concrete skill to combat passive acceptance. | **Generic media literacy is insufficient.** Interventions must target the specific cognitive shortcuts (like seizing on headlines) that NFC promotes. |
| **External: Redesign Choice Architectures** | **Alter Platform Design to Encourage Deliberation** | Implement **"friction" features** such as prompts encouraging users to read an article before sharing, or brief delays before content is reshared. Design algorithms to **deprioritize the amplification of content based solely on moral outrage and emotional reactivity**. Counteract the **"news-finds-me" perception** by designing feeds that introduce diverse, high-quality sources. | **The environment must nudge users toward more reflective engagement.** The current architecture optimizes for the very seizing behavior that leads to vulnerability. |
| **External: Source & Content Curation** | **Improve Source Signaling & Context** | Move beyond simple, often ignored source labels. Explore **crowdsourced judgments of news source quality** to inform ranking[^6]. Provide **contextual corrections** directly adjacent to or within posts containing false claims, which can be more effective than standalone fact-check pages. | **Emphasizing publisher identity alone is not enough**[^6]. Interventions must integrate credibility cues and corrections seamlessly into the consumption flow. |

**Synthesizing the Intervention Pathway:** A comprehensive approach requires layering these strategies. **At the individual level, the goal is to cultivate a mindset that values accuracy over speed and is comfortable with provisional conclusions.** This can be achieved through education that pairs general critical thinking with specific inoculations against common rhetorical tricks. Teaching about the "break-in-the-message effect," for instance, directly arms individuals against a manipulation tactic that exploits NFC[^13].

**At the platform and societal level, the goal is to reshape the information environment to make the path of least resistance a more reflective one.** This involves ethical platform design that acknowledges the psychological vulnerabilities of users. Algorithms should be tuned not only for engagement but for integrity, reducing the viral velocity of unverified, high-emotion content. Public policy can encourage transparency in algorithmic curation and support independent research into platform effects.

**Crucially, interventions must be deployed with an understanding of the evidence.** For example, while debunking is necessary, it must be done skillfully to avoid the familiarity backfire effect. Similarly, prebunking has shown great promise but requires upfront investment in creating and disseminating educational content. The most effective ecosystem will be one where **informed individuals navigate information environments designed to support, rather than undermine, their epistemic well-being.** By addressing both the need for closure within and the amplifiers without, society can build greater resilience against the pervasive threat of misinformation.

## 6 Limitations, Contradictions, and Future Research Directions

This concluding chapter provides a critical synthesis of the limitations, unresolved contradictions, and promising future directions within the research landscape linking need for closure (NFC) to misinformation acceptance. It systematically analyzes the mixed empirical evidence, highlighting the complex and contingent nature of the relationship. The chapter then delineates concrete, evidence-based avenues for future research, drawing on the reference materials to propose studies that address methodological gaps, cultural moderators, temporal dynamics, neurocognitive underpinnings, and the development of more effective interventions. This chapter serves as a forward-looking conclusion, identifying the key questions that must be answered to advance a more nuanced, globally applicable, and actionable understanding of the psychological drivers of misinformation.

### 6.1 Critical Limitations and Mixed Empirical Findings

The current body of research on NFC and misinformation is marked by significant methodological constraints and a pattern of mixed or contingent findings, which limit the strength and generalizability of conclusions.

**Methodological Constraints and Sampling Biases:** A pervasive limitation is the **over-reliance on convenient samples**, such as online crowdsourcing platforms (e.g., MTurk, Prolific) and university students, which are not representative of the general population[^28]. These samples are predominantly young, educated, urban, and digitally literate, systematically excluding rural, offline, low-literacy, and vulnerable populations (e.g., refugees, children)[^28]. This creates a **Western, Educated, Industrialized, Rich, and Democratic (WEIRD) bias**, meaning existing findings and interventions may not apply to the global majority[^28]. Furthermore, **survey designs often inflate misperception rates** by lacking explicit "Don't know" options or encouraging guessing, leading to overestimates of misinformation acceptance[^29].

**Contradictory and Context-Dependent Evidence:** The empirical relationship between NFC and related outcomes is not straightforward. A key contradiction emerges in clinical research: while both NFC and the jumping-to-conclusions (JTC) bias are independently associated with delusion-proneness, **there is no evidence of a direct relationship between NFC and JTC itself**[^16]. This discounts the intuitive view that a motivated need for certainty directly causes hasty data-gathering. Additionally, the NFC construct itself shows internal complexity: **intolerance of ambiguity correlates positively with delusion-proneness, whereas decisiveness correlates negatively**[^16]. This indicates that the discomfort with uncertainty, not the confidence in quick decisions, may be the more critical driver of susceptibility to aberrant beliefs.

**Disentangling Ability, Motivation, and Other Factors:** Comparative predictive models reveal that the role of NFC must be understood relative to other powerful factors. **Fluid intelligence (cognitive ability for reasoning) is consistently associated with a more pronounced correction effect**, meaning individuals with higher fluid intelligence adjust their attitudes more effectively after misinformation is corrected[^11]. In stark contrast, **Need for Cognition (NFCog), the motivation to engage in effortful thinking, does not significantly influence the size of the correction effect**[^11]. This critical dissociation suggests that successfully overcoming misinformation depends more on cognitive *ability* than on thinking *motivation*. Moreover, factors like **institutional distrust and epistemic vice (e.g., indifference to truth) appear to be stronger predictors of real-world conspiracy beliefs than NFC**[^30][^31]. These findings underscore that NFC is often a secondary or moderating variable within a complex ecosystem of cognitive, motivational, and social factors.

### 6.2 Unresolved Contradictions and Key Questions

The literature presents several fundamental contradictions that challenge simplistic narratives and point to essential unknowns requiring investigation.

**The Primacy of Distrust vs. Epistemic Motivation:** Longitudinal survey evidence presents a clear contradiction: while NFC is a consistent, weak predictor of conspiracy beliefs, **pre-existing and concurrent institutional (political/medical) trust is the overwhelmingly dominant predictor**[^30]. This raises the pivotal question: **Is NFC a primary psychological driver of misinformation acceptance, or is it a secondary amplifier that becomes significant primarily in contexts of low trust?** The evidence suggests that societal-level vulnerabilities (distrust) may be more consequential than individual-level traits (NFC) in explaining widespread belief in falsehoods.

**Cultural Non-Universality of the NFC Effect:** Cross-cultural research reveals that the behavioral and psychological consequences of NFC are not universal but are profoundly shaped by cultural context. In collectivist cultures (e.g., China), higher NFC predicts **greater trust in government and higher compliance with public health measures**, mediated by this trust[^30]. Conversely, in individualist cultures (e.g., United States), NFC **does not predict government trust** and instead directly predicts more depressive symptoms and lower life satisfaction[^30]. This contradiction forces a reevaluation: **Does NFC inherently lead to acceptance of authoritative (or misinformative) narratives, or does it simply motivate adherence to the dominant epistemic norms of one's cultural context?**

**Inconsistent Persistence of Misinformation:** Experimental evidence on the continued influence effect (CIE)—where misinformation impacts reasoning even after correction—is mixed. Some studies find a significant CIE[^11][^32], while others do not[^11][^33]. This inconsistency points to unresolved questions about **the necessary conditions for misinformation to persist**. Is persistence dependent on specific attributes of the misinformation, the coherence of the narrative it supports, the credibility of the correction source, or individual differences in traits like NFC or fluid intelligence? The lack of a reliable, robust CIE across paradigms is a major theoretical and empirical challenge.

### 6.3 Proposed Avenues for Future Research

To address these limitations and contradictions, future research should pursue a structured agenda focused on methodological rigor, cultural specificity, mechanistic understanding, and real-world applicability.

**1. Cross-Cultural and Contextual Moderators:** Future studies must systematically investigate cultural and contextual moderators. Building on the US-China comparative findings[^30] and studies in Greece/Portugal[^34], research should employ experimental and longitudinal designs across diverse societies to test how **Hofstede's cultural dimensions (individualism-collectivism, uncertainty avoidance, power distance) shape the NFC-misinformation pathway**[^35][^36]. For instance, does high NFC lead to greater susceptibility to misinformation from in-group authorities in high power-distance cultures? Similarly, research must move beyond WEIRD samples to include **rural, offline, and vulnerable populations** using methods like digital ethnography and partnerships with community organizations[^28][^37].

**2. Temporal Dynamics and Cognitive Integration:** Research should explore the temporal boundaries of NFC-influenced biases. Longitudinal studies can track how **the relationship between NFC and belief in specific misinformation evolves over time**, especially after repeated corrections. Experimental work should investigate how **NFC interacts with the decay of the illusory truth effect over varying intervals**[^38][^39]. Does high NFC slow the decay of false beliefs by reinforcing the 'freeze' on initial judgments? Additionally, neuroimaging studies (fMRI) should build on findings related to the neural correlates of the CIE[^32] and conspiracy beliefs[^40] to **map the brain mechanisms through which NFC affects the encoding, retrieval, and integration of corrective information**.

**3. Differentiated Mechanisms and Hybrid Models:** Research must move beyond treating NFC as a monolithic predictor. Studies should **disaggregate the subcomponents of NFC** (e.g., intolerance of ambiguity, decisiveness, closed-mindedness) to determine which facets are most predictive of specific misinformation outcomes (e.g., initial acceptance vs. resistance to correction). Furthermore, future models should **integrate NFC with other key constructs**—such as fluid intelligence, epistemic vice, media locus of control, and social identity—in comprehensive "hybrid" models to assess their relative and interactive contributions to misinformation susceptibility[^41][^42].

**4. Ecologically Valid and Culturally Sensitive Interventions:** Intervention research must transition from strictly controlled lab settings to real-world social media environments[^37]. Studies should test the efficacy of **NFC-tailored interventions**, such as prebunking modules that specifically warn about the "break-in-the-message" effect or training in source evaluation heuristics that counteract the desire for simple, authoritative answers. Crucially, these interventions must be **co-designed and tested across diverse cultural and media landscapes**, including visually-focused platforms (e.g., TikTok, Instagram) and non-textual formats, which are currently understudied[^37][^28]. Evaluating the long-term sustainability and real-world impact of such interventions is essential.

In conclusion, advancing the field requires a concerted shift from seeking simple, universal correlations to embracing complexity, context, and mechanism. By addressing the outlined limitations and pursuing the proposed research avenues, scholars can develop a more robust, culturally-attuned, and practically useful science of misinformation—one that empowers individuals and societies to navigate the modern information ecosystem with greater resilience and critical discernment.

# 参考内容如下：
[^1]:[The need for cognitive closure.](https://psycnet.apa.org/record/2009-12071-023)
[^2]:[Need For Closure Scale (NFCS) - Arie Kruglanski](https://www.kruglanskiarie.com/need-for-closure)
[^3]:[Need for (Cognitive) Closure Scale (NFCS)](https://sjdm.org/dmidi/Need_for_(Cognitive)_Closure_Scale.html)
[^4]:[Misinformation and disinformation](https://www.apa.org/topics/journalism-facts/misinformation-disinformation)
[^5]:[Misinformation versus disinformation, explained](https://www.thefire.org/research-learn/misinformation-versus-disinformation-explained)
[^6]:[The psychological drivers of misinformation belief and its ...](https://www.nature.com/articles/s44159-021-00006-y)
[^7]:[When Does an Individual Accept Misinformation? An ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC9093560/)
[^8]:[Using a signal detection approach to understand the ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC11443571/)
[^9]:[the role of need for cognitive closure in retrieval-induced ...](https://www.academia.edu/8020288/THE_ROLE_OF_NEED_FOR_COGNITIVE_CLOSURE_IN_RETRIEVAL_INDUCED_FORGETTING_AND_MISINFORMATION_EFFECTS_IN_EYEWITNESS_MEMORY)
[^10]:[Need for cognitive closure, political trust, and belief in ...](https://www.frontiersin.org/journals/social-psychology/articles/10.3389/frsps.2024.1447313/pdf)
[^11]:[Fluid intelligence but not need for cognition is associated ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC11411052/)
[^12]:[Need for cognitive closure, political trust, and belief in ...](https://www.frontiersin.org/journals/social-psychology/articles/10.3389/frsps.2024.1447313/full)
[^13]:[Need for Closure Moderates the Break in the Message Effect](https://pmc.ncbi.nlm.nih.gov/articles/PMC5124571/)
[^14]:['Jumping to conclusions' data-gathering bias in psychosis ...](https://www.sciencedirect.com/science/article/abs/pii/S0272735815301707)
[^15]:[Need for closure and jumping-to-conclusions in delusion- ...](https://pubmed.ncbi.nlm.nih.gov/11838027/)
[^16]:[Need for closure, jumping to conclusions, and ...](https://pubmed.ncbi.nlm.nih.gov/16772859/)
[^17]:[Susceptibility to online misinformation: A systematic meta- ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC11588074/)
[^18]:[Lazy, not biased: Susceptibility to partisan fake news is ...](https://www.sciencedirect.com/science/article/abs/pii/S001002771830163X)
[^19]:[Epistemic Vice Predicts Acceptance of COVID-19 ...](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3644356)
[^20]:[Social Media Algorithms - Misinformation on Social Media](https://library.queens.edu/misinformation-on-social-media/algorithms)
[^21]:[Human-algorithm interactions help explain the spread of ...](https://www.sciencedirect.com/science/article/abs/pii/S2352250X23002154)
[^22]:[AI Echo Chambers: How Algorithms Shape Reality, ...](https://www.techrxiv.org/users/892815/articles/1270092-ai-echo-chambers-how-algorithms-shape-reality-influence-democracy-and-fuel-misinformation)
[^23]:[The Role of Social Media Algorithms in Reinforcing Herd ...](https://medium.com/business-expert-news/the-role-of-social-media-algorithms-in-reinforcing-herd-behavior-while-simulating-user-autonomy-fc2caa6959ae)
[^24]:[Social Drivers and Algorithmic Mechanisms on Digital Media](https://pmc.ncbi.nlm.nih.gov/articles/PMC11373151/)
[^25]:[Examining the role of news-finds-me perceptions in ...](https://www.sciencedirect.com/science/article/abs/pii/S0747563224002991)
[^26]:["I Know News Will Find Me": Examining the Relationship ...](https://pubmed.ncbi.nlm.nih.gov/38166580/)
[^27]:[Overconfidence in news judgments is associated with false ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC8201962/)
[^28]:[Towards the study of world misinformation](https://misinforeview.hks.harvard.edu/article/towards-the-study-of-world-misinformation/)
[^29]:[Conceptual and Methodological Challenges](https://sciencespo.hal.science/hal-03700770v1/document)
[^30]:[Need for cognitive closure and trust towards government ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC9255507/)
[^31]:[Can Conspiracy Beliefs Be Beneficial? Longitudinal ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC9896259/)
[^32]:[Keeping Track of 'Alternative Facts': The Neural Correlates ...](https://pubmed.ncbi.nlm.nih.gov/30872047/)
[^33]:[Did he or didn't he? Mixed evidence for the continued ...](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0322045)
[^34]:[Cross-Cultural Perspectives on Fake News: A Comparative ...](https://www.mdpi.com/2078-2489/16/1/41)
[^35]:[Can Cultural Factors Influence Information Disorder?](https://fight-dis.info/Can-Cultural-Factors-Influence-Information-Disorder.html)
[^36]:[Presumed Effects of “Fake News” on the Global Warming ...](https://www.mdpi.com/2071-1050/12/5/2123)
[^37]:[Psychological interventions countering misinformation in ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC9849948/)
[^38]:[A Longitudinal Study of the Illusory Truth Effect](https://journalofcognition.org/articles/10.5334/joc.161)
[^39]:[Is it all about the feeling? Affective and (meta-)cognitive ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC8821071/)
[^40]:[Neural correlates of conspiracy beliefs during information ...](https://pubmed.ncbi.nlm.nih.gov/40419620/)
[^41]:[“I enjoy thinking critically, and I'm in control”: Examining the ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC8631744/)
[^42]:[Who endorses conspiracy theories? A moderated mediation ...](https://pmc.ncbi.nlm.nih.gov/articles/PMC8686206/)
